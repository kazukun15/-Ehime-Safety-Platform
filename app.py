# -*- coding: utf-8 -*-
# æ„›åª›ã‚»ãƒ¼ãƒ•ãƒ†ã‚£ãƒ»ãƒ—ãƒ©ãƒƒãƒˆãƒ•ã‚©ãƒ¼ãƒ  / Ehime Safety Platform  v7.2
# - ãƒ‡ã‚¶ã‚¤ãƒ³åˆ·æ–°ï¼šã‚·ãƒ“ãƒ©/ãƒã‚®é¢¨ã®ãƒã‚ªãƒ•ãƒ¥ãƒ¼ãƒãƒ£ãƒ¼UIï¼ˆãƒ€ãƒ¼ã‚¯/ãƒ©ã‚¤ãƒˆè‡ªå‹•å¯¾å¿œãƒ»ãƒã‚ªãƒ³ã‚°ãƒ©ãƒ‡ãƒ»ã‚«ãƒ¼ãƒ‰ãƒ»ãƒãƒƒãƒ—ãƒ»ãƒŸã‚¯ãƒ­ã‚¤ãƒ³ã‚¿ãƒ©ã‚¯ã‚·ãƒ§ãƒ³ï¼‰
# - ã‚«ãƒ†ã‚´ãƒªåˆ¥ã‚¢ã‚¤ã‚³ãƒ³å±¤ã‚’è¿½åŠ ï¼ˆIcon-like TextLayerï¼‰ã€‚å‡¡ä¾‹ã‚‚ã‚¢ã‚¤ã‚³ãƒ³ï¼‹è‰²ãƒãƒƒãƒ—ã§è¦–èªæ€§å‘ä¸Š
# - æ©Ÿèƒ½ã¯ v7.1.1 ã¨åŒã˜ï¼šçœŒè­¦ã‚¹ã‚¯ãƒ¬ã‚¤ãƒ—â†’è¿‘ä¼¼åº§æ¨™åŒ–â†’pydeckå¯è¦–åŒ–ã€H3ã‚¯ãƒ©ã‚¹ã‚¿ã€è¿‘ä¼¼å††ã€ãƒ•ã‚£ãƒ¼ãƒ‰ã€ãƒšãƒ¼ã‚¸ãƒ³ã‚°
# - å¤–ä¾å­˜APIã‚­ãƒ¼ä¸è¦ã€‚åœ°å›³ã¯GSIã‚¿ã‚¤ãƒ«ï¼ˆæ—¥æœ¬èªï¼‰ã‚’ä½¿ç”¨

import os, re, math, time, json, sqlite3, threading, unicodedata
from dataclasses import dataclass
from datetime import datetime
from typing import Dict, List, Optional, Tuple
from concurrent.futures import ThreadPoolExecutor

import httpx
import requests
import pandas as pd
import streamlit as st
import pydeck as pdk
from bs4 import BeautifulSoup
from rapidfuzz import fuzz, process as rf_process
import h3

APP_TITLE = "æ„›åª›ã‚»ãƒ¼ãƒ•ãƒ†ã‚£ãƒ»ãƒ—ãƒ©ãƒƒãƒˆãƒ•ã‚©ãƒ¼ãƒ  / Ehime Safety Platform"
EHIME_POLICE_URL = "https://www.police.pref.ehime.jp/sokuho/sokuho.htm"
USER_AGENT = "ESP/7.2 (design/neo)"
TIMEOUT = 12
TTL_HTML = 600
MAX_WORKERS = 6

EHIME_PREF_LAT = 33.8390
EHIME_PREF_LON = 132.7650

CITY_NAMES = ["æ¾å±±å¸‚","ä»Šæ²»å¸‚","æ–°å±…æµœå¸‚","è¥¿æ¡å¸‚","å¤§æ´²å¸‚","ä¼Šäºˆå¸‚","å››å›½ä¸­å¤®å¸‚","è¥¿äºˆå¸‚","æ±æ¸©å¸‚","ä¸Šå³¶ç”º","ä¹…ä¸‡é«˜åŸç”º","æ¾å‰ç”º","ç ¥éƒ¨ç”º","å†…å­ç”º","ä¼Šæ–¹ç”º","æ¾é‡ç”º","é¬¼åŒ—ç”º","æ„›å—ç”º"]
CATEGORY_PATTERNS = [
    ("äº¤é€šäº‹æ•…", r"äº¤é€š.*äº‹æ•…|è‡ªè»¢è»Š|ãƒã‚¹|äºŒè¼ª|ä¹—ç”¨|è¡çª|äº¤å·®ç‚¹|å›½é“|çœŒé“|äººèº«äº‹æ•…"),
    ("ç«ç½",     r"ç«ç½|å‡ºç«|å…¨ç„¼|åŠç„¼|å»¶ç„¼"),
    ("æ­»äº¡äº‹æ¡ˆ", r"æ­»äº¡|æ­»äº¡äº‹æ¡ˆ"),
    ("çªƒç›—",     r"çªƒç›—|ä¸‡å¼•|ç›—"),
    ("è©æ¬º",     r"è©æ¬º|é‚„ä»˜é‡‘|æŠ•è³‡è©æ¬º|ç‰¹æ®Šè©æ¬º"),
    ("äº‹ä»¶",     r"å¨åŠ›æ¥­å‹™å¦¨å®³|æ¡ä¾‹é•å|æš´è¡Œ|å‚·å®³|è„…è¿«|å™¨ç‰©æå£Š|é’å°‘å¹´ä¿è­·"),
]
FACILITY_HINT = ["å­¦æ ¡","å°å­¦æ ¡","ä¸­å­¦æ ¡","é«˜æ ¡","å¤§å­¦","ã‚°ãƒ©ã‚¦ãƒ³ãƒ‰","ä½“è‚²é¤¨","å…¬åœ’","é§…","æ¸¯","ç—…é™¢","äº¤å·®ç‚¹"]

# ===== Streamlit åŸºæœ¬è¨­å®š =====
st.set_page_config(page_title="Ehime Safety Platform", layout="wide")
st.markdown(
    """
    <style>
      :root{
        --bg: #0b0f14;
        --panel: #0f141b;
        --panel-2: #121924;
        --text: #e6f1ff;
        --muted: #8aa0b6;
        --accent: #00e0ff;
        --accent-2: #7cffd9;
        --chip: #1a2230;
        --chip-border: #2b3a4d;
        --glow: 0 0 20px rgba(0,224,255,.25), 0 0 60px rgba(0,224,255,.10);
      }
      @media (prefers-color-scheme: light){
        :root{
          --bg: #f7fafc;
          --panel: #ffffff;
          --panel-2: #f1f5f9;
          --text: #10212f;
          --muted: #516170;
          --accent: #007aff;
          --accent-2: #00b894;
          --chip: #f6f9fc;
          --chip-border: #dfe7ef;
          --glow: 0 0 0 transparent, 0 0 0 transparent;
        }
      }
      html, body, .stApp { background: var(--bg); color: var(--text); }
      /* ã‚¿ã‚¤ãƒˆãƒ«ãƒãƒ¼ */
      .topbar{
        position: sticky; top:0; z-index:10;
        padding: 14px 16px; margin: -16px -16px 14px -16px;
        border-bottom: 1px solid var(--chip-border);
        background: linear-gradient(180deg, rgba(0,224,255,.06), transparent 60%), var(--panel);
        box-shadow: var(--glow);
      }
      .brand{
        display:flex; align-items:center; gap:10px; font-weight:800; 
        letter-spacing:.2px; font-size:1.05rem;
      }
      .brand .id{ 
        width:28px; height:28px; border-radius:8px; 
        display:grid; place-items:center; 
        background: linear-gradient(135deg, var(--accent), var(--accent-2));
        color:#00131a; font-weight:900;
      }
      .subnote{ color: var(--muted); font-size:.85rem; margin-top:4px}
      /* ãƒãƒƒãƒ—ãƒœã‚¿ãƒ³ï¼ˆã‚«ãƒ†ã‚´ãƒªãƒˆã‚°ãƒ«ï¼‰ */
      .fab-bar { display:flex; flex-wrap:wrap; gap:8px; padding:8px 0 0 0 }
      .chip{
        border-radius:999px; border:1px solid var(--chip-border); 
        padding:6px 10px; background:var(--chip); color:var(--text);
        box-shadow: 0 2px 8px rgba(0,0,0,.08);
        font-size:.9rem; display:inline-flex; align-items:center; gap:8px; cursor:pointer;
      }
      .chip.active{
        border-color: transparent; 
        background: linear-gradient(135deg, rgba(0,224,255,.20), rgba(124,255,217,.10)), var(--chip);
        box-shadow: var(--glow);
      }
      .chip .ico{ font-weight:900; opacity:.9 }
      /* ã‚«ãƒ¼ãƒ‰ãƒ•ã‚£ãƒ¼ãƒ‰ */
      .feed-card{
        background: var(--panel);
        border-radius:14px; border:1px solid var(--chip-border);
        margin-bottom:10px; padding:12px 14px; 
        box-shadow: 0 1px 2px rgba(0,0,0,.12);
      }
      .feed-scroll { max-height:62vh; overflow-y:auto; padding-right:6px }
      .feed-title{ font-weight:700; }
      .feed-meta{ color: var(--muted); font-size:.9rem; margin-top:2px }
      .feed-pred{ margin-top:4px; color: var(--accent-2); font-size:.9rem }
      /* å‡¡ä¾‹ï¼ˆåœ°å›³ã®ä¸‹ï¼‰ */
      .legend { 
        font-size:.95rem; background:var(--panel); border:1px solid var(--chip-border); 
        border-radius:12px; padding:10px 12px; box-shadow: 0 1px 2px rgba(0,0,0,.15);
      }
      .legend .item { display:inline-flex; align-items:center; margin-right:14px; margin-bottom:6px}
      .dot { width:12px; height:12px; border-radius:50%; display:inline-block; margin-right:6px; border:1px solid #00000022}
      .legend .ic { margin:0 6px 0 8px; opacity:.9; font-weight:800 }
      /* å…¥åŠ›ã‚„ã‚µã‚¤ãƒ‰ãƒãƒ¼ */
      .stSlider > div, .stTextInput>div>div>input { accent-color: var(--accent) }
      .panel {
        background: var(--panel); border:1px solid var(--chip-border); border-radius: 14px; 
        padding: 10px 12px; box-shadow: 0 1px 2px rgba(0,0,0,.15);
      }
      @media (max-width: 640px){ .feed-scroll{max-height:48vh} }
    </style>
    """,
    unsafe_allow_html=True,
)

st.markdown(
    f"""
    <div class="topbar">
      <div class="brand">
        <div class="id">ES</div>
        <div>
          <div>{APP_TITLE}</div>
          <div class="subnote">ä»Šã«å¼·ã„ãƒ»å…ˆã‚’èª­ã‚€ã€‚åœ°å›³ã§ä¸€ç›®ã€è¦ç‚¹ã¯ç°¡æ½”ã€‚</div>
        </div>
      </div>
    </div>
    """, unsafe_allow_html=True
)

# ===== Sidebar =====
with st.sidebar:
    st.markdown("<div class='panel'>", unsafe_allow_html=True)
    st.markdown("#### è¡¨ç¤ºæœŸé–“")
    period = st.select_slider("è¡¨ç¤ºæœŸé–“ã‚’é¸æŠ", ["å½“æ—¥","éå»3æ—¥","éå»7æ—¥","éå»30æ—¥"], value="éå»7æ—¥", label_visibility="collapsed")
    period_days = {"å½“æ—¥":1, "éå»3æ—¥":3, "éå»7æ—¥":7, "éå»30æ—¥":30}[period]

    st.markdown("#### è¡¨ç¤ºå¯†åº¦")
    zoom_like = st.slider("è¡¨ç¤ºå¯†åº¦ï¼ˆç²—â†â†’ç´°ï¼‰", 7, 14, 10)
    fanout_threshold = st.slider("ã‚¹ãƒ‘ã‚¤ãƒ€ãƒ¼å±•é–‹é–¾å€¤", 2, 8, 4)
    label_scale = st.slider("ãƒ©ãƒ™ãƒ«å€ç‡", 0.7, 1.6, 1.0, 0.1)

    st.markdown("#### ã‚¬ã‚¼ãƒƒãƒ†ã‚£ã‚¢")
    gazetteer_path = st.text_input("CSVãƒ‘ã‚¹", "data/gazetteer_ehime.csv")
    use_fuzzy = st.checkbox("ã‚†ã‚‰ãå¯¾å¿œ", True)
    min_fuzzy_score = st.slider("æœ€å°ã‚¹ã‚³ã‚¢", 60, 95, 78)
    st.markdown("</div>", unsafe_allow_html=True)

# ====== SQLite cache ======
@st.cache_resource
def get_sqlite():
    os.makedirs("data", exist_ok=True)
    conn = sqlite3.connect("data/esp_cache.sqlite", check_same_thread=False)
    with conn:
        conn.execute("CREATE TABLE IF NOT EXISTS geocode_cache(key TEXT PRIMARY KEY, lon REAL, lat REAL, type TEXT, created_at TEXT)")
    return conn
conn = get_sqlite(); conn_lock = threading.Lock()

def geocode_cache_get(key:str):
    with conn_lock:
        r = conn.execute("SELECT lon,lat,type FROM geocode_cache WHERE key=?", (key,)).fetchone()
    if r: return float(r[0]), float(r[1]), str(r[2])
    return None

def geocode_cache_put(key:str, lon:float, lat:float, typ:str):
    with conn_lock, conn:
        conn.execute("INSERT OR REPLACE INTO geocode_cache VALUES (?,?,?,?,datetime('now'))", (key, lon, lat, typ))

# ===== Helpers =====
def _norm(s: str) -> str:
    s = unicodedata.normalize('NFKC', s or '').strip()
    s = re.sub(r"\s+", " ", s)
    return s

@dataclass
class IncidentItem:
    heading: str
    body: str
    incident_date: Optional[str]

# ===== Fetch & Parse =====
@st.cache_data(ttl=TTL_HTML)
def fetch_ehime_html() -> str:
    headers = {"User-Agent": USER_AGENT}
    last_err = None
    for attempt in range(3):
        try:
            with httpx.Client(headers=headers, timeout=TIMEOUT) as client:
                r = client.get(EHIME_POLICE_URL)
                if r.status_code in (429, 503):
                    raise httpx.HTTPStatusError("rate limited", request=None, response=r)
                r.raise_for_status()
                enc = r.encoding or 'utf-8'
                try:
                    r.encoding = r.apparent_encoding or enc
                except Exception:
                    r.encoding = enc
                return r.text
        except Exception as e:
            last_err = e
            time.sleep(0.6 * (attempt + 1))
    try:
        r = requests.get(EHIME_POLICE_URL, headers=headers, timeout=TIMEOUT)
        r.raise_for_status()
        r.encoding = r.apparent_encoding or r.encoding or "utf-8"
        return r.text
    except Exception:
        st.warning("é€Ÿå ±ãƒšãƒ¼ã‚¸ã®å–å¾—ã«å¤±æ•—ã—ã¾ã—ãŸã€‚ç©ºãƒ‡ãƒ¼ã‚¿ã§è¡¨ç¤ºã—ã¾ã™ã€‚")
        return "<html><body></body></html>"

def parse_items(html: str) -> List[IncidentItem]:
    soup = BeautifulSoup(html, "html.parser")
    text = soup.get_text("\n", strip=True)
    text = re.sub(r"ã€æ„›åª›çœŒè­¦ã‹ã‚‰ã®ãŠé¡˜ã„ï¼ã€‘[\s\S]*?(?=â– |$)", "", text)
    lines = [ln for ln in text.split("\n") if ln.strip()]
    items, cur = [], None
    for ln in lines:
        if ln.startswith("â– "):
            if cur: items.append(cur)
            cur = {"heading": ln.strip(), "body": []}
        else:
            if cur: cur["body"].append(ln.strip())
    if cur: items.append(cur)

    out: List[IncidentItem] = []
    today = datetime.now().date(); cy = today.year
    for b in items:
        h = b.get("heading", ""); body = " ".join(b.get("body", []))
        m = re.search(r"ï¼ˆ?(\d{1,2})æœˆ(\d{1,2})æ—¥", h)
        d = None
        if m:
            mm, dd = int(m.group(1)), int(m.group(2)); y = cy
            try:
                dt = datetime(y, mm, dd).date();  y -= 1 if dt > today else 0
                d = datetime(y, mm, dd).date().isoformat()
            except: d = None
        out.append(IncidentItem(h.replace("â– ", "").strip(), body, d))
    return out

# ===== NLPï¼ˆè»½é‡ãƒ«ãƒ¼ãƒ«ï¼‰ =====
def rule_extract(it: IncidentItem) -> Dict:
    t = it.heading + " " + it.body
    cat = "ãã®ä»–"
    for name, pat in CATEGORY_PATTERNS:
        if re.search(pat, t): cat = name; break
    muni = None
    for c in CITY_NAMES:
        if c in t: muni = c; break
    places = []
    for hint in FACILITY_HINT:
        places += re.findall(rf"([\w\u3040-\u30ff\u4e00-\u9fffA-Za-z0-9]+{hint})", t)[:2]
    s = re.sub(r"\s+", " ", it.body).strip()
    s = s[:120] + ("â€¦" if len(s)>120 else "")
    return {"category":cat,"municipality":muni,"place_strings":list(dict.fromkeys(places))[:3],
            "summary": s or it.heading, "date": it.incident_date}

# ===== Gazetteer =====
@st.cache_resource
def load_gazetteer(path:str) -> Optional[pd.DataFrame]:
    try:
        df = pd.read_csv(path)
        for c in ("name","type","lon","lat"):
            if c not in df.columns: return None
        df["alt_names"] = df.get("alt_names", "").fillna("")
        return df
    except Exception:
        return None

class GazetteerIndex:
    def __init__(self, df: pd.DataFrame):
        self.df = df.reset_index(drop=True)
        self.keys = (df["name"].astype(str) + " | " + df["alt_names"].astype(str)).tolist()
    def search(self, q:str, min_score:int=78) -> Optional[Tuple[float,float,str]]:
        m = self.df[(self.df["name"].str.contains(q, na=False)) | (self.df["alt_names"].str.contains(q, na=False))]
        if not m.empty:
            r = m.iloc[0]; return float(r["lon"]), float(r["lat"]), str(r["type"])  # type: ignore
        hit = rf_process.extractOne(q, self.keys, scorer=fuzz.token_set_ratio)
        if hit and hit[1] >= min_score:
            r = self.df.iloc[hit[2]]; return float(r["lon"]), float(r["lat"]), str(r["type"])  # type: ignore
        return None

# ===== Nominatim =====
def nominatim_geocode(name:str, municipality:Optional[str]) -> Optional[Tuple[float,float]]:
    try:
        q = f"{name} {municipality or ''} æ„›åª›çœŒ æ—¥æœ¬".strip()
        headers = {"User-Agent": USER_AGENT}
        params = {"q": q, "format": "jsonv2", "limit": 1}
        for i in range(3):
            r = requests.get("https://nominatim.openstreetmap.org/search", params=params, headers=headers, timeout=TIMEOUT)
            if r.status_code in (429,503):
                time.sleep(0.6 * (i+1)); continue
            r.raise_for_status()
            arr = r.json()
            if isinstance(arr, list) and arr:
                return float(arr[0]["lon"]), float(arr[0]["lat"])
        return None
    except Exception:
        return None

# ===== H3/Cluster =====
def h3_cell_from_latlng(lat: float, lon: float, res: int) -> str:
    if hasattr(h3, "geo_to_h3"): return h3.geo_to_h3(lat, lon, res)  # v3
    return h3.latlng_to_cell(lat, lon, res)  # v4

def h3_latlng_from_cell(cell: str) -> Tuple[float,float]:
    if hasattr(h3, "h3_to_geo"): lat, lon = h3.h3_to_geo(cell); return lat, lon  # v3
    lat, lon = h3.cell_to_latlng(cell); return lat, lon  # v4

def h3_res_from_zoom(zoom_val:int) -> int:
    return {7:5,8:6,9:7,10:8,11:9,12:9,13:10,14:10}.get(zoom_val, 8)

def cluster_points(df: pd.DataFrame, zoom_val:int) -> List[Dict]:
    res = h3_res_from_zoom(zoom_val)
    groups: Dict[str, List[Dict]] = {}
    for _, r in df.iterrows():
        lon, lat = float(r["lon"]), float(r["lat"])
        cell = h3_cell_from_latlng(lat, lon, res)
        d = r.to_dict(); d["cell"] = cell
        groups.setdefault(cell, []).append(d)
    centers: List[Dict] = []
    for cell, rows in groups.items():
        lat, lon = h3_latlng_from_cell(cell)
        centers.append({"cell":cell, "lon":lon, "lat":lat, "count":len(rows), "rows":rows})
    return centers

# ===== Text helpers / Prediction =====
def short_summary(s: str, max_len: int = 64) -> str:
    s = re.sub(r"\s+", " ", s or "").strip()
    return (s[:max_len] + ("â€¦" if len(s) > max_len else "")) if s else ""

def make_prediction(category:str, muni:Optional[str]) -> str:
    if category == "è©æ¬º":       return "SNSã‚„æŠ•è³‡ã®èª˜ã„ã«æ³¨æ„ã€‚é€é‡‘å‰ã«å®¶æ—ã‚„è­¦å¯Ÿã¸ç›¸è«‡ã€‚"
    if category == "äº¤é€šäº‹æ•…":   return "å¤•æ–¹ã‚„é›¨å¤©ã®äº¤å·®ç‚¹ã§å¢—ãˆã‚„ã™ã„ã€‚æ¨ªæ–­ã¨å³å·¦æŠ˜ã«æ³¨æ„ã€‚"
    if category == "çªƒç›—":       return "è‡ªè»¢è»Šãƒ»è»Šä¸¡ã®æ–½éŒ ã¨é˜²çŠ¯ç™»éŒ²ã€‚å¤œé–“ã®ç„¡æ–½éŒ æ”¾ç½®ã‚’é¿ã‘ã‚‹ã€‚"
    if category == "ç«ç½":       return "ä¹¾ç‡¥æ™‚ã¯å±‹å¤–ç«æ°—ã«é…æ…®ã€‚é›»æºå‘¨ã‚Šãƒ»å–«ç…™ã®å§‹æœ«ã‚’å†ç¢ºèªã€‚"
    if category == "äº‹ä»¶":       return "ä¸å¯©é€£çµ¡ã¯è¨˜éŒ²ã‚’æ®‹ã—é€šå ±ã€‚å­¦æ ¡ãƒ»å…¬å…±æ–½è¨­å‘¨è¾ºã§æ„è­˜ã‚’ã€‚"
    if category == "æ­»äº¡äº‹æ¡ˆ":   return "è©³ç´°ã¯å‡ºå…¸ã§ç¢ºèªã€‚å‘¨è¾ºã§ã¯æ•‘æ€¥æ´»å‹•ã«é…æ…®ã€‚"
    return "åŒç¨®äº‹æ¡ˆãŒç¶šãå¯èƒ½æ€§ã€‚å‡ºå…¸ã§æœ€æ–°ã‚’ç¢ºèªã€‚"

# ===== Pipeline =====
with st.spinner("é€Ÿå ±ã‚’å–å¾—ä¸­â€¦"):
    html = fetch_ehime_html()
raw_items = parse_items(html)

extracted: List[Dict] = []
for it in raw_items:
    ex = rule_extract(it)
    ex["heading"] = it.heading
    extracted.append(ex)

gdf = load_gazetteer(gazetteer_path)
idx = GazetteerIndex(gdf) if gdf is not None else None

def resolve_one(ex: Dict) -> Dict:
    muni = ex.get("municipality"); places = ex.get("place_strings") or []
    if idx is not None:
        for ptxt in places:
            hit = idx.search(ptxt, min_fuzzy_score if use_fuzzy else 101)
            if hit: lon, lat, typ = hit; return {"lon":lon, "lat":lat, "type":typ}
        if muni:
            hit = idx.search(muni, min_fuzzy_score if use_fuzzy else 101)
            if hit: lon, lat, typ = hit; return {"lon":lon, "lat":lat, "type":typ}
    if muni:
        for ptxt in places:
            ll = nominatim_geocode(ptxt, muni)
            if ll: return {"lon":ll[0], "lat":ll[1], "type":"facility"}
        ll = nominatim_geocode(muni, None)
        if ll: return {"lon":ll[0], "lat":ll[1], "type":"city"}
    return {"lon":EHIME_PREF_LON, "lat":EHIME_PREF_LAT, "type":"pref"}

with ThreadPoolExecutor(max_workers=MAX_WORKERS) as exctr:
    results = list(exctr.map(resolve_one, extracted))

rows: List[Dict] = []
for ex, loc in zip(extracted, results):
    typ = loc.get("type","city")
    radius = {"facility":300,"intersection":250,"town":600,"chome":600,"oaza":900,"aza":900,"city":2000}.get(typ, 1200)
    rows.append({
        "lon": float(loc["lon"]), "lat": float(loc["lat"]),
        "category": ex["category"],
        "summary": short_summary(ex["summary"], 60),
        "municipality": ex.get("municipality") or "",
        "radius_m": int(radius),
        "pred": make_prediction(ex["category"], ex.get("municipality")),
        "src": EHIME_POLICE_URL,
    })

df = pd.DataFrame(rows)

# ===== ã‚«ãƒ†ã‚´ãƒªè‰²ãƒ»ã‚¢ã‚¤ã‚³ãƒ³ï¼ˆUnicodeç°¡æ˜“ã€‚IconLayerç›¸å½“ã‚’ TextLayerã§å®Ÿç¾ï¼‰ =====
CAT_STYLE = {
    "äº¤é€šäº‹æ•…": {"color":[255, 99, 99, 230],  "radius":86, "icon":"â–²"},   # alert-red
    "ç«ç½":     {"color":[255, 140, 66, 230], "radius":88, "icon":"ğŸ”¥"},  # orange-fire
    "æ­»äº¡äº‹æ¡ˆ": {"color":[197, 128, 255, 230],"radius":92, "icon":"âœ–"},   # purple
    "çªƒç›—":     {"color":[98, 165, 255, 230], "radius":78, "icon":"ğŸ”“"},  # blue
    "è©æ¬º":     {"color":[70, 205, 180, 230], "radius":78, "icon":"âš "},   # teal-yellow
    "äº‹ä»¶":     {"color":[255, 210, 64, 230], "radius":82, "icon":"ï¼"},   # amber
    "ãã®ä»–":   {"color":[130, 150, 166, 210], "radius":70, "icon":"ãƒ»"},  # gray
}

# ===== ãƒˆã‚°ãƒ«ï¼ˆãƒãƒƒãƒ—UIï¼‰ =====
active = st.session_state.get("active_cats") or {k: True for k in CAT_STYLE}
chips = ["<div class='fab-bar'>"]
for k, v in CAT_STYLE.items():
    on = active.get(k, True)
    cls = "chip active" if on else "chip"
    ico = v["icon"]
    chips.append(
        f"<button class='{cls}' onclick=\\\"window.parent.postMessage({{{{'type':'toggle','cat':'{k}'}}}},'*')\\\">"
        f"<span class='ico'>{ico}</span>{k}</button>"
    )
chips.append("</div>")
st.markdown("".join(chips), unsafe_allow_html=True)

st.components.v1.html("""
<script>
window.addEventListener('message', (e)=>{
  if(!e.data || e.data.type!=='toggle') return;
  const cat = e.data.cat; const url = new URL(window.location);
  const key = 'cat_'+encodeURIComponent(cat); const cur = url.searchParams.get(key);
  url.searchParams.set(key, cur==='0' ? '1' : '0'); window.location.replace(url.toString());
});
</script>
""", height=0)

qs = st.query_params
for k in list(CAT_STYLE.keys()):
    kk = "cat_"+k
    if kk in qs: active[k] = (qs[kk] != "0")
st.session_state["active_cats"] = active

vis_df = df[df["category"].apply(lambda c: active.get(str(c), True))]

# ===== H3ã‚¯ãƒ©ã‚¹ã‚¿ =====
centers = []
if not vis_df.empty:
    def h3_res_from_zoom(zoom_val:int) -> int:
        return {7:5,8:6,9:7,10:8,11:9,12:9,13:10,14:10}.get(zoom_val, 8)
    def cluster_points(df: pd.DataFrame, zoom_val:int) -> List[Dict]:
        res = h3_res_from_zoom(zoom_val)
        groups: Dict[str, List[Dict]] = {}
        for _, r in df.iterrows():
            lon, lat = float(r["lon"]), float(r["lat"])
            cell = h3_cell_from_latlng(lat, lon, res)
            d = r.to_dict(); d["cell"] = cell
            groups.setdefault(cell, []).append(d)
        centers: List[Dict] = []
        for cell, rows in groups.items():
            lat, lon = h3_latlng_from_cell(cell)
            centers.append({"cell":cell, "lon":lon, "lat":lat, "count":len(rows), "rows":rows})
        return centers
    centers = cluster_points(vis_df, 10)

# ===== ãƒ¬ã‚¤ãƒ¤æ§‹ç¯‰ï¼ˆScatter + Text 2ç¨®ï¼šç¸¦ãƒ©ãƒ™ãƒ« + ã‚¢ã‚¤ã‚³ãƒ³ï¼‰ =====
hex_points = [{"position":[c["lon"],c["lat"]],"count":c["count"]} for c in centers]
points: List[Dict] = []
icon_labels: List[Dict] = []
mini_labels_fg: List[Dict] = []
mini_labels_bg: List[Dict] = []
polys: List[Dict] = []

def spiderfy(clon: float, clat: float, n: int, base_px: int = 16, gap_px: int = 8):
    out = []; rpx = base_px
    for k in range(n):
        ang = math.radians(137.5 * k)
        dx = rpx*math.cos(ang); dy = rpx*math.sin(ang)
        dlon = dx / (111320 * math.cos(math.radians(clat))); dlat = dy / 110540
        out.append((clon + dlon, clat + dlat)); rpx += gap_px
    return out

MAX_LABELS = 400
for c in centers:
    cnt = c["count"]; clat, clon = c["lat"], c["lon"]
    if cnt <= 4:
        offs = spiderfy(clon, clat, cnt, base_px=16, gap_px=8)
        for (lon, lat), row in zip(offs, c["rows"]):
            sty = CAT_STYLE.get(row["category"], CAT_STYLE["ãã®ä»–"])
            points.append({
                "position":[lon,lat], "color":sty["color"], "radius":sty["radius"],
                "c":row["category"], "s":row["summary"], "m":row.get("municipality",""),
                "pred": row.get("pred",""), "src": row.get("src", EHIME_POLICE_URL),
                "r": int(row.get("radius_m", 600)),
                "ico": sty["icon"],
            })
            # ã‚¢ã‚¤ã‚³ãƒ³ï¼ˆé‡ãªã‚‰ãªã„ã‚ˆã†å°‘ã—ä¸Šã«ï¼‰
            icon_labels.append({"position":[lon,lat], "label":sty["icon"], "tcolor":[255,255,255,240], "offset":[0,-2]})
            # ã‚¹ãƒ¢ãƒ¼ãƒ«ç¸¦ãƒ©ãƒ™ãƒ«ï¼ˆ4æ–‡å­—ã‚’ç¸¦ä¸¦ã³ï¼‰
            if len(mini_labels_fg) < MAX_LABELS:
                vtxt = (row["summary"] or "")[:4]
                vtxt = "\n".join(list(vtxt))
                offset_px = int(-14*label_scale)
                mini_labels_bg.append({"position":[lon,lat],"label":vtxt,"tcolor":[0,0,0,220],"offset":[0,offset_px]})
                mini_labels_fg.append({"position":[lon,lat],"label":vtxt,"tcolor":[255,255,255,235],"offset":[0,offset_px]})
            polys.append({"lon":lon,"lat":lat,"r":int(row.get("radius_m",600))})
    else:
        points.append({"position":[clon,clat],"color":[90,90,90,200],"radius":70,"c":f"{cnt}ä»¶","s":"å‘¨è¾ºã«å¤šæ•°","m":"","pred":"","src":EHIME_POLICE_URL,"r":0,"ico":"â—"})
        icon_labels.append({"position":[clon,clat], "label":"â—", "tcolor":[255,255,255,230], "offset":[0,-2]})
        if len(mini_labels_fg) < MAX_LABELS:
            mini_labels_bg.append({"position":[clon,clat],"label":str(cnt),"tcolor":[0,0,0,220],"offset":[0,-12]})
            mini_labels_fg.append({"position":[clon,clat],"label":str(cnt),"tcolor":[255,255,255,235],"offset":[0,-12]})

# è¿‘ä¼¼å††
def circle_coords(lon: float, lat: float, radius_m: int = 300, n: int = 64):
    coords = []
    r_earth = 6378137.0
    dlat = radius_m / r_earth
    dlon = radius_m / (r_earth * math.cos(math.radians(lat)))
    for i in range(n):
        ang = 2 * math.pi * i / n
        lat_i = lat + math.degrees(dlat * math.sin(ang))
        lon_i = lon + math.degrees(dlon * math.cos(math.radians(lat)))
        coords.append([lon_i, lat_i])
    coords.append(coords[0]); return coords

geo_features = []
for p in points:
    if p.get("r",0) > 0:
        geo_features.append({"type":"Feature","geometry":{"type":"Polygon","coordinates":[circle_coords(p["position"][0], p["position"][1], int(p["r"]))]},"properties":{}})
geojson = {"type":"FeatureCollection","features": geo_features}

# ===== ãƒ¬ã‚¤ã‚¢ã‚¦ãƒˆ =====
col_map, col_feed = st.columns([7,5], gap="large")

with col_map:
    TILES = {
        "GSI æ·¡è‰²": {"url": "https://cyberjapandata.gsi.go.jp/xyz/pale/{z}/{x}/{y}.png", "max_zoom": 18},
        "GSI æ¨™æº–": {"url": "https://cyberjapandata.gsi.go.jp/xyz/std/{z}/{x}/{y}.png", "max_zoom": 18},
    }
    TILE = TILES["GSI æ·¡è‰²"]
    layers = [
        pdk.Layer("TileLayer", data=TILE["url"], min_zoom=0, max_zoom=TILE.get("max_zoom",18), tile_size=256, opacity=1.0),
        pdk.Layer("HexagonLayer", data=[{"position":x["position"],"count":x["count"]} for x in hex_points],
                  get_position="position", get_elevation_weight="count", elevation_scale=5, elevation_range=[0,800],
                  extruded=False, radius=500, coverage=0.9, opacity=0.22, pickable=False),
        pdk.Layer("GeoJsonLayer", data=geojson, pickable=False, stroked=True, filled=True,
                  get_line_width=2, get_line_color=[0,224,255], get_fill_color=[0,224,255,40], auto_highlight=False),
        pdk.Layer("ScatterplotLayer", data=points, get_position="position", get_fill_color="color", get_radius="radius",
                  pickable=True, radius_min_pixels=3, radius_max_pixels=60),
        # ã‚¢ã‚¤ã‚³ãƒ³ï¼ˆæ–‡å­—ï¼‰ãƒ¬ã‚¤ãƒ¤
        pdk.Layer("TextLayer", data=icon_labels, get_position="position", get_text="label", get_color="tcolor",
                  get_size=14, get_pixel_offset="offset", get_alignment_baseline="bottom", get_text_anchor="middle"),
        # ç¸¦ãƒ©ãƒ™ãƒ«ï¼ˆèƒŒæ™¯â†’å‰æ™¯ï¼‰
        pdk.Layer("TextLayer", data=mini_labels_bg, get_position="position", get_text="label", get_color="tcolor",
                  get_size=int(12*label_scale), get_pixel_offset="offset", get_alignment_baseline="bottom", get_text_anchor="middle"),
        pdk.Layer("TextLayer", data=mini_labels_fg, get_position="position", get_text="label", get_color="tcolor",
                  get_size=int(12*label_scale), get_pixel_offset="offset", get_alignment_baseline="bottom", get_text_anchor="middle"),
    ]

    tooltip = {
        "html": "<b>{c}</b><br/>{s}<br/>{m}<br/>äºˆæ¸¬: {pred}<br/><a href='{src}' target='_blank'>å‡ºå…¸</a>",
        "style": {"backgroundColor":"rgba(10,15,20,.96)","color":"#e6f1ff","maxWidth":"280px","whiteSpace":"normal",
                  "wordBreak":"break-word","lineHeight":1.4,"fontSize":"12px","padding":"10px 12px",
                  "borderRadius":"12px","border":"1px solid #2b3a4d","boxShadow":"0 8px 32px rgba(0,224,255,.15)"}
    }

    deck = pdk.Deck(
        layers=layers,
        initial_view_state=pdk.ViewState(latitude=EHIME_PREF_LAT, longitude=EHIME_PREF_LON, zoom=9),
        tooltip=tooltip, map_provider=None, map_style=None
    )
    st.pydeck_chart(deck, use_container_width=True, height=540)

    # å‡¡ä¾‹ï¼ˆã‚¢ã‚¤ã‚³ãƒ³ï¼‹è‰²ãƒ‰ãƒƒãƒˆï¼‰
    legend_items = []
    for k, v in CAT_STYLE.items():
        rgba = f"rgba({v['color'][0]}, {v['color'][1]}, {v['color'][2]}, {v['color'][3]/255:.9f})"
        legend_items.append(f"<span class='item'><span class='ic'>{v['icon']}</span><span class='dot' style='background:{rgba}'></span>{k}</span>")
    st.markdown(f"<div class='legend'>{''.join(legend_items)}<div style='margin-top:6px;color:var(--muted);font-size:.85rem'>å††ã¯æ¦‚ã­ã®ç¯„å›²ã€‚è©³ç´°ã¯å‡ºå…¸ã‚’ç¢ºèªã€‚</div></div>", unsafe_allow_html=True)

with col_feed:
    st.markdown("<div class='panel'>", unsafe_allow_html=True)
    st.markdown("#### é€Ÿå ±ãƒ•ã‚£ãƒ¼ãƒ‰")
    q = st.text_input("ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ï¼ˆå¸‚ç”ºåã‚„è¦ç‚¹ï¼‰")
    feed = df.copy()
    if q:
        feed = feed[feed.apply(lambda r: q in (r.get("summary") or "") or q in (r.get("municipality") or ""), axis=1)]
    total = len(feed)
    page_size = st.slider("ãƒšãƒ¼ã‚¸å½“ãŸã‚Šä»¶æ•°", 10, 50, 30, 5)
    pages = max(1, (total + page_size - 1)//page_size)
    page = st.number_input("ãƒšãƒ¼ã‚¸", 1, pages, 1)
    view = feed.iloc[(page-1)*page_size : page*page_size]

    html_list = ["<div class='feed-scroll'>"]
    for _, r in view.iterrows():
        cat = r.get('category',''); icon = CAT_STYLE.get(cat, CAT_STYLE["ãã®ä»–"])["icon"]
        html_list.append("<div class='feed-card'>")
        html_list.append(f"<div class='feed-title'>{icon} {cat}</div>")
        html_list.append(f"<div>{r.get('summary','')}</div>")
        muni = r.get('municipality') or ''
        if muni: html_list.append(f"<div class='feed-meta'>{muni}</div>")
        html_list.append(f"<div class='feed-pred'>äºˆæ¸¬: {r.get('pred','')}</div>")
        html_list.append(f"<div class='feed-meta'><a href='{r.get('src')}' target='_blank'>å‡ºå…¸</a></div>")
        html_list.append("</div>")
    html_list.append("</div>")
    st.markdown("\n".join(html_list), unsafe_allow_html=True)
    st.markdown("</div>", unsafe_allow_html=True)

st.caption("åœ°å›³: å›½åœŸåœ°ç†é™¢ / æƒ…å ±: çœŒè­¦é€Ÿå ±ã€‚ç·Šæ€¥æ™‚ã¯110ãƒ»119ã¸ã€‚")
